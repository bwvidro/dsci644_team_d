{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General idea\n",
    "1. Clean dataset => dfClean\n",
    "2. Vectorize words => to probability density\n",
    "3. Perform logistic regression on vectorized words \n",
    "    of scales of reviews 0 (0,.1),1 (.2,.3) ,2 (.4,.5),3 (.6,.7) ,4 (.8,.9, 1) reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\danxg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\danxg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['appID', 'reviewerName', 'reviewText', 'reviewerRating', 'reviewDate',\n",
       "       'textAnalytics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data set and stop words\n",
    "import pandas as pd\n",
    "import re \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "rawData = pd.read_csv (r'.\\AppReview.csv')\n",
    "#df=df1.sample(n=1000)\n",
    "len(rawData.index)\n",
    "rawData.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danxg\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerRating</th>\n",
       "      <th>reviewDate</th>\n",
       "      <th>textAnalytics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Eric Hansen</td>\n",
       "      <td>Love it! WELL worth the money for the full ver...</td>\n",
       "      <td>5</td>\n",
       "      <td>2017/07/07 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Jacob N.</td>\n",
       "      <td>There's an awful bug that doesn't allow you to...</td>\n",
       "      <td>2</td>\n",
       "      <td>2017/08/29 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Higgins Family</td>\n",
       "      <td>Would be 5 stars except for the bugs.... For e...</td>\n",
       "      <td>4</td>\n",
       "      <td>2017/10/02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rajko Dikmann</td>\n",
       "      <td>Worked perfect until a few weeks ago. Then bro...</td>\n",
       "      <td>2</td>\n",
       "      <td>2017/09/28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Sergei Garcia</td>\n",
       "      <td>Hands down the best browser on the play store!...</td>\n",
       "      <td>5</td>\n",
       "      <td>2017/07/09 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appID    reviewerName                                         reviewText  \\\n",
       "0      3     Eric Hansen  Love it! WELL worth the money for the full ver...   \n",
       "1      3        Jacob N.  There's an awful bug that doesn't allow you to...   \n",
       "2      3  Higgins Family  Would be 5 stars except for the bugs.... For e...   \n",
       "3      3   Rajko Dikmann  Worked perfect until a few weeks ago. Then bro...   \n",
       "4      3   Sergei Garcia  Hands down the best browser on the play store!...   \n",
       "\n",
       "   reviewerRating           reviewDate  textAnalytics  \n",
       "0               5  2017/07/07 00:00:00            NaN  \n",
       "1               2  2017/08/29 00:00:00            NaN  \n",
       "2               4  2017/10/02 00:00:00            NaN  \n",
       "3               2  2017/09/28 00:00:00            NaN  \n",
       "4               5  2017/07/09 00:00:00            NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData_v1=rawData[rawData[\"reviewerName\"]!=\"A Google User\"]\n",
    "rawData_v1[\"reviewerRating\"]=rawData[\"reviewerRating\"]*10/2\n",
    "rawData_v1=rawData_v1.astype({\"reviewerRating\": int})\n",
    "rawData_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData_v1.groupby(\"reviewerRating\").nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerRating\n",
       "1     8501\n",
       "2     4376\n",
       "3     7571\n",
       "4    15218\n",
       "5    55085\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frames = []\n",
    "# for i in range(1,6,1):\n",
    "#     frames.append(rawData_v1[rawData_v1[\"reviewerRating\"]==i/10].sample(n=1000, replace=False))\n",
    "\n",
    "# df=pd.concat(frames,ignore_index =True)\n",
    "# len(df.index)\n",
    "#df=rawData_v1.sample(n=5000)\n",
    "df=rawData_v1\n",
    "#df.head()\n",
    "df.groupby(\"reviewerRating\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus of stop words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processes a review and returns a list of words\n",
    "def review_to_words(review, string = True, remove_stopwords=True):\n",
    "    # Remove HTML\n",
    "    #review_text = BeautifulSoup(review).get_text()\n",
    "    review_text=review\n",
    "    # Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    # Convert words to lower case and split them\n",
    "    thesewords = review_text.lower().split()\n",
    "    # Ignore non=english words\n",
    "#     englishWords = words.words()\n",
    "#     thesewords = [w for w in thesewords if w in englishWords]\n",
    "\n",
    "    \n",
    "    # Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        thesewords = [w for w in thesewords if not w in stops]\n",
    "    if string:\n",
    "        return \" \".join(thesewords)\n",
    "    else:\n",
    "        return thesewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up text\n",
    "#Remove non-ascii text\n",
    "#Remove all rows missing reviewerName\n",
    "def fixString(x):\n",
    "    return x.encode('ascii',errors='ignore')\n",
    "\n",
    "# df[[\"reviewText\"]]=df[[\"reviewText\"]].apply(lambda x: str(x[\"reviewText\"]).encode('ascii',errors='ignore').decode(), axis=1)\n",
    "# df[[\"reviewerName\"]]=df[[\"reviewerName\"]].apply(lambda x: str(x[\"reviewerName\"]).encode('ascii',errors='ignore').decode(), axis=1)\n",
    "df[[\"reviewText\"]]=df[[\"reviewText\"]].apply(lambda x: review_to_words(x[\"reviewText\"]), axis=1)\n",
    "df[[\"reviewerName\"]]=df[[\"reviewerName\"]].apply(lambda x: str(x[\"reviewerName\"]).encode('ascii',errors='ignore').decode(), axis=1)\n",
    "\n",
    "dfCleaned=df[df['reviewText'].str.strip().astype(bool)]\n",
    "dfCleaned=dfCleaned[df['reviewerName'].str.strip().astype(bool)]\n",
    "\n",
    "#\n",
    "#dfCleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "storedDFCleaned=\"dfCleaned_raw\"\n",
    "dfCleaned.to_pickle(storedDFCleaned)\n",
    "#dfCleaned=pd.read_pickle(storedDFCleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize words\n",
    "### This is based on \n",
    "https://towardsdatascience.com/latent-semantic-analysis-sentiment-classification-with-python-5f657346f6a3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(dfCleaned[\"reviewText\"])\n",
    "\n",
    "X = tfidf.transform(dfCleaned[\"reviewText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awful bug allow use space bar want type search term url box ruined whole experience free browsers like dee browser one without awful bugs believe paid app full review'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleaned.iloc[1][\"reviewText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4528846823706622]\n"
     ]
    }
   ],
   "source": [
    "print([X[1, tfidf.vocabulary_['awful']]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling part\n",
    "1. Leverage the raw vector count and the tf-idf weighted version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfCleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love well worth money full version came ad blo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awful bug allow use space bar want type search...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>would stars except bugs example incognito tab ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worked perfect weeks ago browsing experience s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hands best browser play store even flagship de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positivity\n",
       "0  love well worth money full version came ad blo...           1\n",
       "1  awful bug allow use space bar want type search...           0\n",
       "2  would stars except bugs example incognito tab ...           1\n",
       "3  worked perfect weeks ago browsing experience s...           0\n",
       "4  hands best browser play store even flagship de...           1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df[df['reviewerRating'] != 3]\n",
    "df['Positivity'] = np.where(df['reviewerRating'] > 3, 1, 0)\n",
    "cols = ['appID', 'reviewerName', 'reviewerRating', 'reviewDate', 'textAnalytics']\n",
    "df.drop(cols, axis=1, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 67566 entries with 22.63% negative, 77.37% positive\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.reviewText\n",
    "y = df.Positivity\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "print(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(X_train),\n",
    "                                                                             (len(X_train[y_train == 0]) / (len(X_train)*1.))*100,\n",
    "                                                                            (len(X_train[y_train == 1]) / (len(X_train)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set has total 22522 entries with 22.32% negative, 77.68% positive\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(X_test),\n",
    "                                                                             (len(X_test[y_test == 0]) / (len(X_test)*1.))*100,\n",
    "                                                                            (len(X_test[y_test == 1]) / (len(X_test)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "def accuracy_summary(pipeline, X_train, y_train, X_test, y_test):\n",
    "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for trigram with stop words (Tfidf)\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Test result for 10000 features\n",
      "accuracy score: 85.80%\n",
      "Test result for 20000 features\n",
      "accuracy score: 86.06%\n",
      "Test result for 30000 features\n",
      "accuracy score: 86.06%\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "n_features = np.arange(10000,30001,10000)\n",
    "def nfeature_accuracy_checker(vectorizer=cv, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=rf):\n",
    "    result = []\n",
    "    print(classifier)\n",
    "    print(\"\\n\")\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        print(\"Test result for {} features\".format(n))\n",
    "        nfeature_accuracy = accuracy_summary(checker_pipeline, X_train, y_train, X_test, y_test)\n",
    "        result.append((n,nfeature_accuracy))\n",
    "    return result\n",
    "tfidf = TfidfVectorizer()\n",
    "print(\"Result for trigram with stop words (Tfidf)\\n\")\n",
    "feature_result_tgt = nfeature_accuracy_checker(vectorizer=tfidf,ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.59      0.65      5026\n",
      "    positive       0.89      0.94      0.91     17496\n",
      "\n",
      "    accuracy                           0.86     22522\n",
      "   macro avg       0.81      0.76      0.78     22522\n",
      "weighted avg       0.85      0.86      0.85     22522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cv = CountVectorizer(max_features=30000,ngram_range=(1, 3))\n",
    "pipeline = Pipeline([\n",
    "        ('vectorizer', cv),\n",
    "        ('classifier', rf)\n",
    "    ])\n",
    "sentiment_fit = pipeline.fit(X_train, y_train)\n",
    "y_pred = sentiment_fit.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['negative','positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60163    great app org mode files wish free freedom sup...\n",
       "84085    fan hi really keen activating super sensor one...\n",
       "17149          liked mh u player must app haha full review\n",
       "56477    ok miui seems ignore dnd setting would thought...\n",
       "60868    errors extremely useful easy use often search ...\n",
       "                               ...                        \n",
       "25195    comes handy especially age social media nevert...\n",
       "53324                                    works full review\n",
       "50026          really works great really works full review\n",
       "50996                                     nice full review\n",
       "80700           favourite move material design full review\n",
       "Name: reviewText, Length: 67566, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for trigram with stop words (Tfidf)\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "\n",
      "Test result for 10000 features\n",
      "accuracy score: 87.31%\n",
      "Test result for 20000 features\n",
      "accuracy score: 87.34%\n",
      "Test result for 30000 features\n",
      "accuracy score: 87.44%\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000, multi_class='auto')\n",
    "\n",
    "cv = CountVectorizer()\n",
    "n_features = np.arange(10000,30001,10000)\n",
    "def nfeature_accuracy_checker(vectorizer=cv, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=clf):\n",
    "    result = []\n",
    "    print(classifier)\n",
    "    print(\"\\n\")\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        print(\"Test result for {} features\".format(n))\n",
    "        nfeature_accuracy = accuracy_summary(checker_pipeline, X_train, y_train, X_test, y_test)\n",
    "        result.append((n,nfeature_accuracy))\n",
    "    return result\n",
    "tfidf = TfidfVectorizer()\n",
    "print(\"Result for trigram with stop words (Tfidf)\\n\")\n",
    "feature_result_tgt = nfeature_accuracy_checker(vectorizer=tfidf,ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.63      0.68      5026\n",
      "    positive       0.90      0.94      0.92     17496\n",
      "\n",
      "    accuracy                           0.87     22522\n",
      "   macro avg       0.82      0.78      0.80     22522\n",
      "weighted avg       0.86      0.87      0.86     22522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cv = CountVectorizer(max_features=30000,ngram_range=(1, 3))\n",
    "pipeline = Pipeline([\n",
    "        ('vectorizer', cv),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "sentiment_fit = pipeline.fit(X_train, y_train)\n",
    "y_pred = sentiment_fit.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['negative','positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
