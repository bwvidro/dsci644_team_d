{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General idea\n",
    "1. Clean dataset => dfClean\n",
    "2. Vectorize words => to probability density\n",
    "3. Perform logistic regression on vectorized words \n",
    "    of scales of reviews 0 (0,.1),1 (.2,.3) ,2 (.4,.5),3 (.6,.7) ,4 (.8,.9, 1) reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111143"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data set and stop words\n",
    "import pandas as pd\n",
    "import re \n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "df1 = pd.read_csv (r'.\\AppReview.csv')\n",
    "df=df1\n",
    "len(df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus of stop words\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processes a review and returns a list of words\n",
    "def review_to_words(review, string = True, remove_stopwords=True):\n",
    "    # Remove HTML\n",
    "    #review_text = BeautifulSoup(review).get_text()\n",
    "    review_text=review\n",
    "    # Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    # Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    # Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    if string:\n",
    "        return \" \".join(words)\n",
    "    else:\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerRating</th>\n",
       "      <th>reviewDate</th>\n",
       "      <th>textAnalytics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Eric Hansen</td>\n",
       "      <td>love well worth money full version came ad blo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017/07/07 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Jacob N.</td>\n",
       "      <td>awful bug allow use space bar want type search...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2017/08/29 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Higgins Family</td>\n",
       "      <td>would stars except bugs example incognito tab ...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2017/10/02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rajko Dikmann</td>\n",
       "      <td>worked perfect weeks ago browsing experience s...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2017/09/28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Sergei Garcia</td>\n",
       "      <td>hands best browser play store even flagship de...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017/07/09 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111138</th>\n",
       "      <td>343</td>\n",
       "      <td>heera d</td>\n",
       "      <td>good less power consumer full review</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1-September-2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111139</th>\n",
       "      <td>343</td>\n",
       "      <td>Maulik Upadhyay</td>\n",
       "      <td>xperia pro nice change would nice full review</td>\n",
       "      <td>0.8</td>\n",
       "      <td>21-August-2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111140</th>\n",
       "      <td>343</td>\n",
       "      <td>Lezlie Coleman</td>\n",
       "      <td>willl full review</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24-September-2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111141</th>\n",
       "      <td>343</td>\n",
       "      <td>Taher Bhai</td>\n",
       "      <td>great wonderful app samsung galaxy full review</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14-August-2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111142</th>\n",
       "      <td>343</td>\n",
       "      <td>Eli Lopez</td>\n",
       "      <td>nice wt said without problemz full review</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14-August-2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110480 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        appID     reviewerName  \\\n",
       "0           3      Eric Hansen   \n",
       "1           3         Jacob N.   \n",
       "2           3   Higgins Family   \n",
       "3           3    Rajko Dikmann   \n",
       "4           3    Sergei Garcia   \n",
       "...       ...              ...   \n",
       "111138    343          heera d   \n",
       "111139    343  Maulik Upadhyay   \n",
       "111140    343   Lezlie Coleman   \n",
       "111141    343       Taher Bhai   \n",
       "111142    343        Eli Lopez   \n",
       "\n",
       "                                               reviewText  reviewerRating  \\\n",
       "0       love well worth money full version came ad blo...             1.0   \n",
       "1       awful bug allow use space bar want type search...             0.4   \n",
       "2       would stars except bugs example incognito tab ...             0.8   \n",
       "3       worked perfect weeks ago browsing experience s...             0.4   \n",
       "4       hands best browser play store even flagship de...             1.0   \n",
       "...                                                   ...             ...   \n",
       "111138               good less power consumer full review             0.8   \n",
       "111139      xperia pro nice change would nice full review             0.8   \n",
       "111140                                  willl full review             0.6   \n",
       "111141     great wonderful app samsung galaxy full review             1.0   \n",
       "111142          nice wt said without problemz full review             1.0   \n",
       "\n",
       "                 reviewDate  textAnalytics  \n",
       "0       2017/07/07 00:00:00            NaN  \n",
       "1       2017/08/29 00:00:00            NaN  \n",
       "2       2017/10/02 00:00:00            NaN  \n",
       "3       2017/09/28 00:00:00            NaN  \n",
       "4       2017/07/09 00:00:00            NaN  \n",
       "...                     ...            ...  \n",
       "111138     1-September-2013            NaN  \n",
       "111139       21-August-2013            NaN  \n",
       "111140    24-September-2013            NaN  \n",
       "111141       14-August-2013            NaN  \n",
       "111142       14-August-2013            NaN  \n",
       "\n",
       "[110480 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean up text\n",
    "#Remove non-ascii text\n",
    "#Remove all rows missing reviewerName\n",
    "def fixString(x):\n",
    "    return x.encode('ascii',errors='ignore')\n",
    "\n",
    "# df[[\"reviewText\"]]=df[[\"reviewText\"]].apply(lambda x: str(x[\"reviewText\"]).encode('ascii',errors='ignore').decode(), axis=1)\n",
    "# df[[\"reviewerName\"]]=df[[\"reviewerName\"]].apply(lambda x: str(x[\"reviewerName\"]).encode('ascii',errors='ignore').decode(), axis=1)\n",
    "df[[\"reviewText\"]]=df[[\"reviewText\"]].apply(lambda x: review_to_words(x[\"reviewText\"]), axis=1)\n",
    "df[[\"reviewerName\"]]=df[[\"reviewerName\"]].apply(lambda x: str(x[\"reviewerName\"]).encode('ascii',errors='ignore').decode(), axis=1)\n",
    "\n",
    "dfCleaned=df[df['reviewText'].str.strip().astype(bool)]\n",
    "dfCleaned=dfCleaned[df['reviewerName'].str.strip().astype(bool)]\n",
    "\n",
    "#\n",
    "dfCleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviewText'][0]\n",
    "\n",
    "type(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love well worth money full version came ad blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awful bug allow use space bar want type search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>would stars except bugs example incognito tab ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worked perfect weeks ago browsing experience s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hands best browser play store even flagship de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111138</th>\n",
       "      <td>good less power consumer full review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111139</th>\n",
       "      <td>xperia pro nice change would nice full review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111140</th>\n",
       "      <td>willl full review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111141</th>\n",
       "      <td>great wonderful app samsung galaxy full review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111142</th>\n",
       "      <td>nice wt said without problemz full review</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110480 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText\n",
       "0       love well worth money full version came ad blo...\n",
       "1       awful bug allow use space bar want type search...\n",
       "2       would stars except bugs example incognito tab ...\n",
       "3       worked perfect weeks ago browsing experience s...\n",
       "4       hands best browser play store even flagship de...\n",
       "...                                                   ...\n",
       "111138               good less power consumer full review\n",
       "111139      xperia pro nice change would nice full review\n",
       "111140                                  willl full review\n",
       "111141     great wonderful app samsung galaxy full review\n",
       "111142          nice wt said without problemz full review\n",
       "\n",
       "[110480 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleaned[['reviewText']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize words\n",
    "### This is based on \n",
    "https://towardsdatascience.com/sentiment-analysis-a-how-to-guide-with-movie-reviews-9ae335e6bcb2\n",
    "With actual logistic regression:\n",
    "https://towardsdatascience.com/sentiment-classification-with-logistic-regression-analyzing-yelp-reviews-3981678c3b44\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dfReviews = dfCleaned['reviewText']\n",
    "dfTrain, dfTest = train_test_split(dfReviews, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17960     unable register matter method used drops star ...\n",
       "18764                                           full review\n",
       "96536     thanks much dev mediatek support love app upda...\n",
       "63810     nice dark background added thanks yet listenin...\n",
       "100175    unlike everyone else stuck great game stars fu...\n",
       "74331     amazing geocaching app feel like way better of...\n",
       "828                         best app ever found full review\n",
       "99534     fine get level beat literally tried times full...\n",
       "2986                                       love full review\n",
       "87686                                  ok great full review\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Initialize a bag of words\n",
    "#vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 5000) \n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 1000) \n",
    "\n",
    "# Fit transform the data \n",
    "train_feat = vectorizer.fit_transform(dfTrain).toarray()\n",
    "test_feat = vectorizer.transform(dfTest).toarray()\n",
    "\n",
    "\n",
    "# TFIDF train set\n",
    "tfidf_transformer = TfidfTransformer().fit(train_feat)\n",
    "train_tfidf = tfidf_transformer.transform(train_feat)\n",
    " \n",
    "# apply tfidf to test set\n",
    "test_tfidf = tfidf_transformer.transform(test_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest\n",
    "rv1 = pd.Series(\"bad terrible\")\n",
    "rv1_tf = tfidf_transformer.transform(vectorizer.transform(rv1))\n",
    "# individual_x=cx_t.todense()\n",
    "# clf.predict_proba(individual_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    bad terrible\n",
      "dtype: object\n",
      "(0, 866), terrible = 0.7920390356640833\n",
      "(0, 65), bad = 0.6104704464462705\n"
     ]
    }
   ],
   "source": [
    "rv1_tf\n",
    "cx_t = scipy.sparse.coo_matrix(rv1_tf)\n",
    "\n",
    "\n",
    "print(rv1)\n",
    "for i,j,v in zip(cx_t.row, cx_t.col, cx_t.data):\n",
    "    if i!=0:\n",
    "        break\n",
    "    print(\"(%d, %d), %s = %s\" % (i,j,featureNamesList[j], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.58405136e-04, 8.75000494e-01, 7.09665456e-02, 4.50875115e-02,\n",
       "        8.58704402e-03]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_x=cx_t.todense()\n",
    "clf.predict_proba(individual_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "trainYdata = pd.merge(dfTrain.to_frame(), dfCleaned[['reviewerRating']], left_index=True, right_index=True)\n",
    "#determined feature names\n",
    "featureNamesList=vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 17960, Value : unable register matter method used drops star unable register matter method used full review\n",
      "Index : 18764, Value : full review\n",
      "Index : 96536, Value : thanks much dev mediatek support love app update working sony xa single sim phone android best regards lee full review\n",
      "Index : 63810, Value : nice dark background added thanks yet listening user feedback still suggest making playing screen accessible main app tapping notification switch tracks intuitive full review\n",
      "Index : 100175, Value : unlike everyone else stuck great game stars full review\n",
      "Index : 74331, Value : amazing geocaching app feel like way better official one advertisiments best free full review\n",
      "Index : 828, Value : best app ever found full review\n",
      "Index : 99534, Value : fine get level beat literally tried times full review\n",
      "Index : 2986, Value : love full review\n",
      "Index : 87686, Value : ok great full review\n",
      "Index : 4852, Value : works great full review\n"
     ]
    }
   ],
   "source": [
    "# look at data for training\n",
    "type(dfTrain)\n",
    "stopcounter = 0\n",
    "for index, value in dfTrain.items():\n",
    "    print(f\"Index : {index}, Value : {value}\")\n",
    "    stopcounter=stopcounter+1\n",
    "    if stopcounter > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_feat)\n",
    "#len(train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable register matter method used drops star unable register matter method used full review\n",
      "(0, 326), full = 1\n",
      "(0, 523), matter = 2\n",
      "(0, 725), review = 1\n",
      "(0, 816), star = 1\n",
      "(0, 912), unable = 2\n",
      "(0, 931), used = 2\n",
      "\r\n",
      "\r\n",
      "The weighted results\r\n",
      "\n",
      "(0, 931), used = 0.4077722263468781\n",
      "(0, 912), unable = 0.5814796439886868\n",
      "(0, 816), star = 0.25343210340442224\n",
      "(0, 725), review = 0.044723106111382215\n",
      "(0, 523), matter = 0.6537393146892811\n",
      "(0, 326), full = 0.044723106111382215\n"
     ]
    }
   ],
   "source": [
    "# Dump some vectorized words and probablities\n",
    "import scipy.sparse\n",
    "\n",
    "featureNamesList=vectorizer.get_feature_names()\n",
    "type(dfTrain)\n",
    "\n",
    "cx = scipy.sparse.coo_matrix(train_feat)\n",
    "cx2 = scipy.sparse.coo_matrix(train_tfidf)\n",
    "\n",
    "\n",
    "print(dfTrain.iloc[0])\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    if i!=0:\n",
    "        break\n",
    "    print(\"(%d, %d), %s = %s\" % (i,j,featureNamesList[j], v))\n",
    "    \n",
    "print(\"\\r\\n\\r\\nThe weighted results\\r\\n\")\n",
    "for i,j,v in zip(cx2.row, cx2.col, cx2.data):\n",
    "    if i!=0:\n",
    "        break\n",
    "    print(\"(%d, %d), %s = %s\" % (i,j,featureNamesList[j], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "works great htc magic full review\n",
      "(0, 986), works = 0.4565436659616101\n",
      "(0, 725), review = 0.1315889458077755\n",
      "(0, 388), htc = 0.7923073777774721\n",
      "(0, 359), great = 0.3594239820492182\n",
      "(0, 326), full = 0.1315889458077755\n"
     ]
    }
   ],
   "source": [
    "# look at some more data\n",
    "import scipy.sparse\n",
    "\n",
    "featureNamesList=vectorizer.get_feature_names()\n",
    "type(test_tfidf)\n",
    "\n",
    "cx = scipy.sparse.coo_matrix(test_tfidf)\n",
    "\n",
    "print(dfTest.iloc[0])\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    if i!=0:\n",
    "        break\n",
    "    print(\"(%d, %d), %s = %s\" % (i,j,featureNamesList[j], v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling part\n",
    "1. Leverage the raw vector count and the tf-idf weighted version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just looking at some data\n",
    "# train_tfidf\n",
    "# dfTrain\n",
    "# print(df.iloc[105146])\n",
    "# dfTrain\n",
    "# df\n",
    "# train_tfidf.todense()\n",
    "# dfTrain.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70997                     works great htc magic full review\n",
       "56590                                   awesome full review\n",
       "79700     deactivate finger print scanner work active ev...\n",
       "65876                            never got work full review\n",
       "1458                                   nice app full review\n",
       "93515     awesome best app android works perfectly htc o...\n",
       "110748    perfect battery app keeper tried pretty much e...\n",
       "25745     xp tracker count construction runecrafting hp ...\n",
       "103015    works great android used app cyanogenmod andro...\n",
       "46161     google integration note self google voice comm...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.head(10)\n",
    "#type(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trained Y data and test Y data\n",
    "trainYdata = pd.merge(dfTrain.to_frame(), dfCleaned[['reviewerRating']], left_index=True, right_index=True)\n",
    "testYdata = pd.merge(dfTest.to_frame(), dfCleaned[['reviewerRating']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trained X data and test X data\n",
    "trainXdata = train_tfidf.todense()\n",
    "testXdata = test_tfidf.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       appID reviewerName                                         reviewText  \\\n",
      "20624   1410    Edgar Lim  nice work purchased unlocked features support ...   \n",
      "\n",
      "       reviewerRating           reviewDate  textAnalytics  \n",
      "20624             1.0  2016/08/14 00:00:00            NaN  \n",
      "       appID reviewerName                                         reviewText  \\\n",
      "20624   1410    Edgar Lim  nice work purchased unlocked features support ...   \n",
      "\n",
      "       reviewerRating           reviewDate  textAnalytics  \n",
      "20624             1.0  2016/08/14 00:00:00            NaN  \n",
      "                              reviewText  reviewerRating\n",
      "70997  works great htc magic full review             1.0\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13158895 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.35942398\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.79230738 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.13158895\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.45654367 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(dfCleaned[20520:20521])\n",
    "print(df1[20624:20625])\n",
    "print(testYdata[0:1])\n",
    "print(testXdata[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.820349585646472"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data - map the y to ints of scales of reviews 0,1,2,3,4 reviews\n",
    "y = trainYdata[['reviewerRating']]\n",
    "y_int = trainYdata['reviewerRating'].apply(lambda x: 0 if x<.2 else (1 if x<.4 else (2 if x<.6 else (3 if x<.8 else 4))))\n",
    "#y_int = trainYdata['reviewerRating'].apply(lambda x: 0 if x <.5 else 1)\n",
    "\n",
    "X = trainXdata\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000).fit(X, y_int)\n",
    "\n",
    "# Check trained accuracy\n",
    "clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :])\n",
    "clf.score(X, y_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00181229, 0.62981955, 0.09639813, 0.13978012, 0.13218991],\n",
       "       [0.00087273, 0.10516011, 0.03123404, 0.05324641, 0.8094867 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_int_test = testYdata['reviewerRating'].apply(lambda x: 0 if x<.2 else (1 if x<.4 else (2 if x<.6 else (3 if x<.8 else 4))))\n",
    "#y_int_test = testYdata['reviewerRating'].apply(lambda x: 0 if x<.5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8165278783490224"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(testXdata)\n",
    "clf.predict_proba(testXdata)\n",
    "clf.score(testXdata, y_int_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testXdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 42, max_depth = 10, n_jobs=-1)\n",
    "# Train the model on training data\n",
    "clt = rf.fit(X, y_int);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :])\n",
    "clf.score(X, y_int)\n",
    "\n",
    "\n",
    "clf.predict(testXdata)\n",
    "clf.predict_proba(testXdata)\n",
    "clf.score(testXdata, y_int_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
