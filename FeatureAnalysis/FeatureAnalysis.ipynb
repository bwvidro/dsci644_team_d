{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General idea\n",
    "1. Clean dataset => dfClean\n",
    "2. Vectorize words => to probability density\n",
    "3. Perform logistic regression on vectorized words \n",
    "    of scales of reviews 0 (0,.1),1 (.2,.3) ,2 (.4,.5),3 (.6,.7) ,4 (.8,.9, 1) reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111143"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data set and stop words\n",
    "import pandas as pd\n",
    "import re \n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "df111 = pd.read_csv (r'.\\AppReview.csv')\n",
    "#df=df1.sample(n=1000)\n",
    "len(df111.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerRating</th>\n",
       "      <th>reviewDate</th>\n",
       "      <th>textAnalytics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerRating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>338</td>\n",
       "      <td>7763</td>\n",
       "      <td>9911</td>\n",
       "      <td>1</td>\n",
       "      <td>3857</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>294</td>\n",
       "      <td>4012</td>\n",
       "      <td>5134</td>\n",
       "      <td>1</td>\n",
       "      <td>2852</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>329</td>\n",
       "      <td>6965</td>\n",
       "      <td>8883</td>\n",
       "      <td>1</td>\n",
       "      <td>3759</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>386</td>\n",
       "      <td>14010</td>\n",
       "      <td>17645</td>\n",
       "      <td>1</td>\n",
       "      <td>4963</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>473</td>\n",
       "      <td>49121</td>\n",
       "      <td>59953</td>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                appID  reviewerName  reviewText  reviewerRating  reviewDate  \\\n",
       "reviewerRating                                                                \n",
       "0.0                18             1          71               1          60   \n",
       "0.2               338          7763        9911               1        3857   \n",
       "0.4               294          4012        5134               1        2852   \n",
       "0.6               329          6965        8883               1        3759   \n",
       "0.8               386         14010       17645               1        4963   \n",
       "1.0               473         49121       59953               1        5957   \n",
       "\n",
       "                textAnalytics  \n",
       "reviewerRating                 \n",
       "0.0                         1  \n",
       "0.2                        24  \n",
       "0.4                        17  \n",
       "0.6                        17  \n",
       "0.8                        25  \n",
       "1.0                        41  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df111.groupby(\"reviewerRating\").nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = []\n",
    "for i in range(0,12,2):\n",
    "    frames.append(df111[df111[\"reviewerRating\"]==i/10].sample(n=2000, replace=True))\n",
    "\n",
    "df=pd.concat(frames)\n",
    "df.groupby(\"reviewerRating\").nunique()\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus of stop words\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processes a review and returns a list of words\n",
    "def review_to_words(review, string = True, remove_stopwords=True):\n",
    "    # Remove HTML\n",
    "    #review_text = BeautifulSoup(review).get_text()\n",
    "    review_text=review\n",
    "    # Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    # Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    # Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    if string:\n",
    "        return \" \".join(words)\n",
    "    else:\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerRating</th>\n",
       "      <th>reviewDate</th>\n",
       "      <th>textAnalytics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99148</th>\n",
       "      <td>2078</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>exactly isuppose aim touch screen galaxy full ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-December-2010</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56238</th>\n",
       "      <td>1508</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>totally lame wsdot cameras video still photos ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011/02/20 00:00:00</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99185</th>\n",
       "      <td>2078</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>level three weeks bout give full review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27-December-2010</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98690</th>\n",
       "      <td>2078</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>please add levels full review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26-January-2011</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65027</th>\n",
       "      <td>12</td>\n",
       "      <td>A Google User</td>\n",
       "      <td>worked great started connect laptop stinks ful...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30-January-2011</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98405</th>\n",
       "      <td>2078</td>\n",
       "      <td>Iftekhar Akoob</td>\n",
       "      <td>great time waster finished game twice stuck le...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29-March-2013</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>1092</td>\n",
       "      <td>Jo Poochie</td>\n",
       "      <td>smiles selection books awesome enough reading ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015/03/28 00:00:00</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18041</th>\n",
       "      <td>374</td>\n",
       "      <td>JONATHAN CARTER</td>\n",
       "      <td>app full review</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017/09/28 00:00:00</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71848</th>\n",
       "      <td>2131</td>\n",
       "      <td>Jonathan Payn</td>\n",
       "      <td>awesome far best twitter app market like best ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12-October-2015</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63511</th>\n",
       "      <td>985</td>\n",
       "      <td>Jean Kirby</td>\n",
       "      <td>good samsung phone running nougat stock galler...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017/05/31 00:00:00</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11940 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       appID     reviewerName  \\\n",
       "99148   2078    A Google User   \n",
       "56238   1508    A Google User   \n",
       "99185   2078    A Google User   \n",
       "98690   2078    A Google User   \n",
       "65027     12    A Google User   \n",
       "...      ...              ...   \n",
       "98405   2078   Iftekhar Akoob   \n",
       "4929    1092       Jo Poochie   \n",
       "18041    374  JONATHAN CARTER   \n",
       "71848   2131    Jonathan Payn   \n",
       "63511    985       Jean Kirby   \n",
       "\n",
       "                                              reviewText  reviewerRating  \\\n",
       "99148  exactly isuppose aim touch screen galaxy full ...             0.0   \n",
       "56238  totally lame wsdot cameras video still photos ...             0.0   \n",
       "99185            level three weeks bout give full review             0.0   \n",
       "98690                      please add levels full review             0.0   \n",
       "65027  worked great started connect laptop stinks ful...             0.0   \n",
       "...                                                  ...             ...   \n",
       "98405  great time waster finished game twice stuck le...             1.0   \n",
       "4929   smiles selection books awesome enough reading ...             1.0   \n",
       "18041                                    app full review             1.0   \n",
       "71848  awesome far best twitter app market like best ...             1.0   \n",
       "63511  good samsung phone running nougat stock galler...             1.0   \n",
       "\n",
       "                reviewDate  textAnalytics  \n",
       "99148     30-December-2010  -9.223372e+18  \n",
       "56238  2011/02/20 00:00:00  -9.223372e+18  \n",
       "99185     27-December-2010  -9.223372e+18  \n",
       "98690      26-January-2011  -9.223372e+18  \n",
       "65027      30-January-2011  -9.223372e+18  \n",
       "...                    ...            ...  \n",
       "98405        29-March-2013  -9.223372e+18  \n",
       "4929   2015/03/28 00:00:00  -9.223372e+18  \n",
       "18041  2017/09/28 00:00:00  -9.223372e+18  \n",
       "71848      12-October-2015  -9.223372e+18  \n",
       "63511  2017/05/31 00:00:00  -9.223372e+18  \n",
       "\n",
       "[11940 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean up text\n",
    "#Remove non-ascii text\n",
    "#Remove all rows missing reviewerName\n",
    "def fixString(x):\n",
    "    return x.encode('ascii',errors='ignore')\n",
    "\n",
    "# df[[\"reviewText\"]]=df[[\"reviewText\"]].apply(lambda x: str(x[\"reviewText\"]).encode('ascii',errors='ignore').decode(), axis=1)\n",
    "# df[[\"reviewerName\"]]=df[[\"reviewerName\"]].apply(lambda x: str(x[\"reviewerName\"]).encode('ascii',errors='ignore').decode(), axis=1)\n",
    "df[[\"reviewText\"]]=df[[\"reviewText\"]].apply(lambda x: review_to_words(x[\"reviewText\"]), axis=1)\n",
    "df[[\"reviewerName\"]]=df[[\"reviewerName\"]].apply(lambda x: str(x[\"reviewerName\"]).encode('ascii',errors='ignore').decode(), axis=1)\n",
    "\n",
    "dfCleaned=df[df['reviewText'].str.strip().astype(bool)]\n",
    "dfCleaned=dfCleaned[df['reviewerName'].str.strip().astype(bool)]\n",
    "\n",
    "#\n",
    "dfCleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "appID             11940\n",
       "reviewerName      11940\n",
       "reviewText        11940\n",
       "reviewerRating    11940\n",
       "reviewDate        11940\n",
       "textAnalytics     11940\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleaned.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "appID             0.16608\n",
       "reviewerName      0.16608\n",
       "reviewText        0.16608\n",
       "reviewerRating    0.16608\n",
       "reviewDate        0.16608\n",
       "textAnalytics     0.16608\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleaned[dfCleaned['reviewerRating'].apply(lambda x: x==1)].count()/dfCleaned.count()\n",
    "\n",
    "#type(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99148</th>\n",
       "      <td>exactly isuppose aim touch screen galaxy full ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56238</th>\n",
       "      <td>totally lame wsdot cameras video still photos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99185</th>\n",
       "      <td>level three weeks bout give full review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98690</th>\n",
       "      <td>please add levels full review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65027</th>\n",
       "      <td>worked great started connect laptop stinks ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98405</th>\n",
       "      <td>great time waster finished game twice stuck le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>smiles selection books awesome enough reading ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18041</th>\n",
       "      <td>app full review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71848</th>\n",
       "      <td>awesome far best twitter app market like best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63511</th>\n",
       "      <td>good samsung phone running nougat stock galler...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11940 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText\n",
       "99148  exactly isuppose aim touch screen galaxy full ...\n",
       "56238  totally lame wsdot cameras video still photos ...\n",
       "99185            level three weeks bout give full review\n",
       "98690                      please add levels full review\n",
       "65027  worked great started connect laptop stinks ful...\n",
       "...                                                  ...\n",
       "98405  great time waster finished game twice stuck le...\n",
       "4929   smiles selection books awesome enough reading ...\n",
       "18041                                    app full review\n",
       "71848  awesome far best twitter app market like best ...\n",
       "63511  good samsung phone running nougat stock galler...\n",
       "\n",
       "[11940 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCleaned[['reviewText']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize words\n",
    "### This is based on \n",
    "https://towardsdatascience.com/sentiment-analysis-a-how-to-guide-with-movie-reviews-9ae335e6bcb2\n",
    "With actual logistic regression:\n",
    "https://towardsdatascience.com/sentiment-classification-with-logistic-regression-analyzing-yelp-reviews-3981678c3b44\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from gensim.sklearn_api import W2VTransformer\n",
    "\n",
    "# model = W2VTransformer(size=10, min_count=1, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.21650386, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.48438822,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import statements\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dfReviews = dfCleaned['reviewText']\n",
    "dfTrain, dfTest = train_test_split(dfReviews, test_size=.1)\n",
    "\n",
    "# Initialize a bag of words\n",
    "#vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 5000) \n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 1000) \n",
    "\n",
    "# Fit transform the data \n",
    "train_feat = vectorizer.fit_transform(dfTrain).toarray()\n",
    "test_feat = vectorizer.transform(dfTest).toarray()\n",
    "\n",
    "\n",
    "# TFIDF train set\n",
    "tfidf_transformer = TfidfTransformer().fit(train_feat)\n",
    "train_tfidf = tfidf_transformer.transform(train_feat)\n",
    " \n",
    "# apply tfidf to test set\n",
    "test_tfidf = tfidf_transformer.transform(test_feat)\n",
    "\n",
    "train_tfidf.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.matrix'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.21650386 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.48438822 0.        ]]\n",
      "       0         1    2    3    4    5    6    7    8    9    ...  990  991  \\\n",
      "0      0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "1      0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2      0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3      0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4      0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "...    ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "10741  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "10742  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "10743  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "10744  0.0  0.216504  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "10745  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "       992  993  994  995  996  997       998  999  \n",
      "0      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
      "1      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
      "2      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
      "3      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
      "4      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
      "...    ...  ...  ...  ...  ...  ...       ...  ...  \n",
      "10741  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
      "10742  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
      "10743  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
      "10744  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
      "10745  0.0  0.0  0.0  0.0  0.0  0.0  0.484388  0.0  \n",
      "\n",
      "[10746 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "#rv1_tf.todense()\n",
    "a=train_tfidf.todense()\n",
    "print(type(a))\n",
    "pddf = pd.DataFrame(data=train_tfidf.todense())\n",
    "print(type(pddf))\n",
    "print(a)\n",
    "print(pddf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(a[99430,998])\n",
    "# print(pddf[998][99430])\n",
    "\n",
    "# pd.merge(pddf, dfCleaned[['reviewerRating']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest\n",
    "rv1 = pd.Series(\"bad terrible\")\n",
    "rv1_tf = tfidf_transformer.transform(vectorizer.transform(rv1))\n",
    "# individual_x=cx_t.todense()\n",
    "# clf.predict_proba(individual_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    bad terrible\n",
      "dtype: object\n",
      "(0, 860), terrible = 0.7750305703872686\n",
      "(0, 60), bad = 0.6319237414159916\n"
     ]
    }
   ],
   "source": [
    "featureNamesList=vectorizer.get_feature_names()\n",
    "rv1_tf\n",
    "cx_t = scipy.sparse.coo_matrix(rv1_tf)\n",
    "\n",
    "\n",
    "print(rv1)\n",
    "for i,j,v in zip(cx_t.row, cx_t.col, cx_t.data):\n",
    "    if i!=0:\n",
    "        break\n",
    "    print(\"(%d, %d), %s = %s\" % (i,j,featureNamesList[j], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual_x=cx_t.todense()\n",
    "# clf.predict(individual_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10741</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10742</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10743</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10744</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10745</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484388</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10746 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1    2    3    4    5    6    7    8    9    ...  990  991  \\\n",
       "0      0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1      0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2      0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3      0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4      0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...    ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "10741  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "10742  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "10743  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "10744  0.0  0.216504  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "10745  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "       992  993  994  995  996  997       998  999  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...       ...  ...  \n",
       "10741  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "10742  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "10743  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "10744  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  \n",
       "10745  0.0  0.0  0.0  0.0  0.0  0.0  0.484388  0.0  \n",
       "\n",
       "[10746 rows x 1000 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       reviewerRating\n",
       " 99148             0.0\n",
       " 56238             0.0\n",
       " 99185             0.0\n",
       " 98690             0.0\n",
       " 65027             0.0\n",
       " ...               ...\n",
       " 98405             1.0\n",
       " 4929              1.0\n",
       " 18041             1.0\n",
       " 71848             1.0\n",
       " 63511             1.0\n",
       " \n",
       " [11940 rows x 1 columns],\n",
       "                                                reviewText\n",
       " 109560  used work gracefully uploading picture pain le...\n",
       " 109231  app make post sticky button would perfect woul...\n",
       " 94716             keep server settings galaxy full review\n",
       " 71616   best fav star button fav star button automatic...\n",
       " 252     fast smooth provides fastest smoothest browser...\n",
       " ...                                                   ...\n",
       " 12341   essential app us security wise folks good job ...\n",
       " 38514                                         full review\n",
       " 13642   mr lodu aap kya karna kuch samaj hi nai aa ra ...\n",
       " 92816   workaround folder problem workaround able see ...\n",
       " 18619   trash external links crappy youtube videos dow...\n",
       " \n",
       " [10746 rows x 1 columns])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train data\n",
    "trainYdata = pd.merge(dfTrain.to_frame(), dfCleaned[['reviewerRating']], left_index=True, right_index=True)\n",
    "#determined feature names\n",
    "featureNamesList=vectorizer.get_feature_names()\n",
    "\n",
    "trainYdata\n",
    "dfCleaned[['reviewerRating']],dfTrain.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 109560, Value : used work gracefully uploading picture pain let change picture size like really disappointed full review\n",
      "Index : 109231, Value : app make post sticky button would perfect would never need log web interface sticky posts use lot theme full review\n",
      "Index : 94716, Value : keep server settings galaxy full review\n",
      "Index : 71616, Value : best fav star button fav star button automatically colors yellow though im clicking doesnt count annoying please take action reallylove app full review\n",
      "Index : 252, Value : fast smooth provides fastest smoothest browser experience full review\n",
      "Index : 7843, Value : recognise player rooted epic stock player full review\n",
      "Index : 101507, Value : ppl cant beet tip keep middle open n stop complaining full review\n",
      "Index : 99148, Value : exactly isuppose aim touch screen galaxy full review\n",
      "Index : 7960, Value : doubletwist support full review\n",
      "Index : 21216, Value : installing asus zenfone full review\n",
      "Index : 11400, Value : great app cross platform database stays sync via dropbox linux os x windows platforms full review\n"
     ]
    }
   ],
   "source": [
    "# look at data for training\n",
    "type(dfTrain)\n",
    "stopcounter = 0\n",
    "for index, value in dfTrain.items():\n",
    "    print(f\"Index : {index}, Value : {value}\")\n",
    "    stopcounter=stopcounter+1\n",
    "    if stopcounter > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_feat)\n",
    "#len(train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used work gracefully uploading picture pain let change picture size like really disappointed full review\n",
      "(0, 113), change = 1\n",
      "(0, 218), disappointed = 1\n",
      "(0, 328), full = 1\n",
      "(0, 467), let = 1\n",
      "(0, 474), like = 1\n",
      "(0, 629), picture = 2\n",
      "(0, 682), really = 1\n",
      "(0, 710), review = 1\n",
      "(0, 779), size = 1\n",
      "(0, 927), used = 1\n",
      "(0, 980), work = 1\n",
      "\r\n",
      "\r\n",
      "The weighted results\r\n",
      "\n",
      "(0, 980), work = 0.17681132354250811\n",
      "(0, 927), used = 0.23711341310940923\n",
      "(0, 779), size = 0.3463614324765156\n",
      "(0, 710), review = 0.054540329467902895\n",
      "(0, 682), really = 0.22174875297030228\n",
      "(0, 629), picture = 0.624869103742966\n",
      "(0, 474), like = 0.19952579795456063\n",
      "(0, 467), let = 0.3039451690770323\n",
      "(0, 328), full = 0.054540329467902895\n",
      "(0, 218), disappointed = 0.3717821199082091\n",
      "(0, 113), change = 0.276677406761197\n"
     ]
    }
   ],
   "source": [
    "# Dump some vectorized words and probablities\n",
    "import scipy.sparse\n",
    "\n",
    "featureNamesList=vectorizer.get_feature_names()\n",
    "type(dfTrain)\n",
    "\n",
    "cx = scipy.sparse.coo_matrix(train_feat)\n",
    "cx2 = scipy.sparse.coo_matrix(train_tfidf)\n",
    "\n",
    "\n",
    "print(dfTrain.iloc[0])\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    if i!=0:\n",
    "        break\n",
    "    print(\"(%d, %d), %s = %s\" % (i,j,featureNamesList[j], v))\n",
    "    \n",
    "print(\"\\r\\n\\r\\nThe weighted results\\r\\n\")\n",
    "for i,j,v in zip(cx2.row, cx2.col, cx2.data):\n",
    "    if i!=0:\n",
    "        break\n",
    "    print(\"(%d, %d), %s = %s\" % (i,j,featureNamesList[j], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering apps based already icons makes pain use really save everyone time put apps already numix icons list full review\n",
      "(0, 926), use = 0.14045856328170228\n",
      "(0, 874), time = 0.15046358618744912\n",
      "(0, 724), save = 0.21547102265884396\n",
      "(0, 710), review = 0.03897253378963685\n",
      "(0, 682), really = 0.15845358567243056\n",
      "(0, 669), put = 0.22536149257994215\n",
      "(0, 514), makes = 0.20442767150945865\n",
      "(0, 480), list = 0.21614882293934295\n",
      "(0, 396), icons = 0.5475083991717641\n",
      "(0, 328), full = 0.03897253378963685\n",
      "(0, 265), everyone = 0.2722833633783385\n",
      "(0, 44), apps = 0.36142621405564296\n",
      "(0, 27), already = 0.48910909807203506\n"
     ]
    }
   ],
   "source": [
    "# look at some more data\n",
    "import scipy.sparse\n",
    "\n",
    "featureNamesList=vectorizer.get_feature_names()\n",
    "type(test_tfidf)\n",
    "\n",
    "cx = scipy.sparse.coo_matrix(test_tfidf)\n",
    "\n",
    "print(dfTest.iloc[0])\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    if i!=0:\n",
    "        break\n",
    "    print(\"(%d, %d), %s = %s\" % (i,j,featureNamesList[j], v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get trained Y data and test Y data\n",
    "# trainYdata = pd.merge(dfTrain.to_frame(), dfCleaned[['reviewerRating']], left_index=True, right_index=True)\n",
    "# testYdata = pd.merge(dfTest.to_frame(), dfCleaned[['reviewerRating']], left_index=True, right_index=True)\n",
    "# # Get trained X data and test X data\n",
    "# trainXdata = train_tfidf.todense()\n",
    "# testXdata = test_tfidf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train data - map the y to ints of scales of reviews 0,1,2,3,4 reviews\n",
    "# y = trainYdata[['reviewerRating']]\n",
    "# #y_int = trainYdata['reviewerRating'].apply(lambda x: 0 if x<.2 else (1 if x<.4 else (2 if x<.6 else (3 if x<.8 else 4))))\n",
    "# y_int = trainYdata['reviewerRating'].apply(lambda x: x*10)\n",
    "# #y_int = trainYdata['reviewerRating'].apply(lambda x: 0 if x <.5 else 1)\n",
    "# y_int_test = testYdata['reviewerRating'].apply(lambda x: x*10)\n",
    "# X = trainXdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = svm.SVC()\n",
    "# clf.fit(X,y_int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.predict(X[:2, :])\n",
    "# clf.score(X, y_int)\n",
    "\n",
    "\n",
    "# clf.predict(testXdata)\n",
    "# clf.score(testXdata, y_int_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling part\n",
    "1. Leverage the raw vector count and the tf-idf weighted version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Just looking at some data\n",
    "# train_tfidf\n",
    "# dfTrain\n",
    "# print(df.iloc[105146])\n",
    "# dfTrain\n",
    "# df\n",
    "# train_tfidf.todense()\n",
    "# dfTrain.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78652     filtering apps based already icons makes pain ...\n",
       "106194    worst app try altough best app pc tab cant pla...\n",
       "47311                      ni whois user screen full review\n",
       "94483                                   awesome full review\n",
       "68271                                  good app full review\n",
       "61135     need updating though bc lot stuff published pa...\n",
       "94041     work sick rage using sickbeard worked fine mov...\n",
       "96251     stopped work today update claims keys secure s...\n",
       "1030      beautiful clock problem follow actual time ful...\n",
       "87194     works great feature bloat best feature one thi...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.head(10)\n",
    "#type(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trained Y data and test Y data\n",
    "trainYdata = pd.merge(dfTrain.to_frame(), dfCleaned[['reviewerRating']], left_index=True, right_index=True)\n",
    "testYdata = pd.merge(dfTest.to_frame(), dfCleaned[['reviewerRating']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>solid lightweight browser ad blocking basic fe...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>download images anymore please fix full review</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>easy way switch mobile desktop site full review</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>stay frozen continuously continue improving fu...</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>like chrome advertisements makes using chome u...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111134</th>\n",
       "      <td>battery super use full review</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111134</th>\n",
       "      <td>battery super use full review</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111134</th>\n",
       "      <td>battery super use full review</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111134</th>\n",
       "      <td>battery super use full review</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111139</th>\n",
       "      <td>xperia pro nice change would nice full review</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  reviewerRating\n",
       "10      solid lightweight browser ad blocking basic fe...             0.8\n",
       "28         download images anymore please fix full review             0.4\n",
       "30        easy way switch mobile desktop site full review             0.2\n",
       "35      stay frozen continuously continue improving fu...             0.6\n",
       "39      like chrome advertisements makes using chome u...             0.8\n",
       "...                                                   ...             ...\n",
       "111134                      battery super use full review             0.8\n",
       "111134                      battery super use full review             0.8\n",
       "111134                      battery super use full review             0.8\n",
       "111134                      battery super use full review             0.8\n",
       "111139      xperia pro nice change would nice full review             0.8\n",
       "\n",
       "[63325 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainYdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trained X data and test X data\n",
    "trainXdata = train_tfidf.todense()\n",
    "testXdata = test_tfidf.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [appID, reviewerName, reviewText, reviewerRating, reviewDate, textAnalytics]\n",
      "Index: []\n",
      "       appID reviewerName                                         reviewText  \\\n",
      "20624   1410    Edgar Lim  Nice work! I have purchased the unlocked featu...   \n",
      "\n",
      "       reviewerRating           reviewDate  textAnalytics  \n",
      "20624             1.0  2016/08/14 00:00:00            NaN  \n",
      "                                            reviewText  reviewerRating\n",
      "152  latest version buggy latest version fails open...             1.0\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.55801087 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.38543993 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09268024 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.34929192 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09268024 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.40652742 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30161954 0.         0.38031163 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(dfCleaned[20520:20521])\n",
    "print(df1[20624:20625])\n",
    "print(testYdata[0:1])\n",
    "print(testXdata[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62643"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainYdata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10764, 62643]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-856b7b7a11ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainXdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_int\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Check trained accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1527\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10764, 62643]"
     ]
    }
   ],
   "source": [
    "# Train data - map the y to ints of scales of reviews 0,1,2,3,4 reviews\n",
    "y = trainYdata[['reviewerRating']]\n",
    "#y_int = trainYdata['reviewerRating'].apply(lambda x: 0 if x<.2 else (1 if x<.4 else (2 if x<.6 else (3 if x<.8 else 4))))\n",
    "y_int = trainYdata['reviewerRating'].apply(lambda x: x*10)\n",
    "#y_int = trainYdata['reviewerRating'].apply(lambda x: 0 if x <.5 else 1)\n",
    "\n",
    "X = trainXdata\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000).fit(X, y_int)\n",
    "\n",
    "# Check trained accuracy\n",
    "clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :])\n",
    "clf.score(X, y_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.53423095e-04, 1.08950810e-03, 7.45332417e-03, 9.20661122e-02,\n",
       "        6.90839347e-01, 2.08298286e-01],\n",
       "       [1.29446140e-04, 2.31550156e-03, 1.10806381e-03, 4.35405832e-03,\n",
       "        6.45745041e-02, 9.27518426e-01]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_int_test = testYdata['reviewerRating'].apply(lambda x: 0 if x<.2 else (1 if x<.4 else (2 if x<.6 else (3 if x<.8 else 4))))\n",
    "y_int_test = testYdata['reviewerRating'].apply(lambda x: x*10)\n",
    "#y_int_test = testYdata['reviewerRating'].apply(lambda x: 0 if x<.5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6753258508327299"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(testXdata)\n",
    "clf.predict_proba(testXdata)\n",
    "clf.score(testXdata, y_int_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testXdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 42, max_depth = 10, n_jobs=-1)\n",
    "# Train the model on training data\n",
    "clt = rf.fit(X, y_int);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6753258508327299"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :])\n",
    "clf.score(X, y_int)\n",
    "\n",
    "\n",
    "clf.predict(testXdata)\n",
    "clf.predict_proba(testXdata)\n",
    "clf.score(testXdata, y_int_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
